---
title: 'AI - How to start learn in 2023'
date: '2022-12-09'
author: 'Wojciech Cendrzak'
image: '/images/tagged-template-literal-jest-test.png'
tags: 'AI, pytorch'
isPublished: true
---


b) Why deep learning

Deep learning has made a change in a AI landscape in recent past decade. From scientific niche that not fullfilly any promises since 50' when it arosed till now leaving us with mouth opened.

"We break almost all theories about AI" said mr (this profesour) in 2012. (link / photo)

One of that was about release function which, as believed to that time, should be continous.
But there was a problem wiht them. Exp sigmoid function causes a vanishing loss? with neural network with muny layers. It causes that the last layer was learning reasonable fast, one layer before a bit slower, next even more and so on. After all, all network has very slowly progress of learning which basicaly makes them unable to learn deeper networks.

The topic of NN was an ignorable niche and even scientists ware treated not seriously on univercities. "I heard it muny times" saind (profesour) recling his chef teling him to stop working on AI. The scientists didn't even belived the breakthrough can even happen.

Profesour and his team still works on that topic and finally put the right puzzels.

One of them was changing sigmoid function to linear one (name) that basicaly solved problem of wanishing gradient and now learning networks with more deep layers stop to be a problem anymore.



